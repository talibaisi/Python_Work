{"cells":[{"metadata":{},"cell_type":"markdown","source":"This Kernel uses [TPOT AutoML](https://epistasislab.github.io/tpot/) tool(open source & based on Scikit-learn)  to stochastically produces a pipeline using Genetic programming with most accuracy based on training data.\nTPOT generates a python file that has recommended model, the I run the model code on the training data and then predict the target for the testing data and export the submission file. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"#TPOT AutoML tool\nfrom tpot import TPOTClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np # linear algebra\nnp.set_printoptions(precision=2)\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas import DataFrame\n#Parallelism\nimport joblib\nfrom joblib import Parallel, delayed,parallel_backend\n\n\n# Preprocessing, modelling and evaluating\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Imputer,MaxAbsScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,mean_squared_error, mean_absolute_error\nfrom sklearn import svm\n\n## Hyperopt modules\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Credit for: \n*  [Titanic_Kaggle](https://github.com/EpistasisLab/tpot/blob/master/tutorials/Titanic_Kaggle.ipynb)\n\n*  [My paper using DNA Sequence Alignment](http://www.wseas.us/e-library/transactions/systems/2008/27-535.pdf)\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"%%time\ndf_trans = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ndf_test_trans = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n\ndf_id = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ndf_test_id = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n\ndf_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)\ndf_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical columns"},{"metadata":{"trusted":false},"cell_type":"code","source":"cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Enconding categorical features"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nfor col in cat_cols:\n    if col in df_train.columns:\n        le = preprocessing.LabelEncoder()\n        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n        df_test[col] = le.transform(list(df_test[col].astype(str).values))   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing high correlated features"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nX_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\ny_train = df_train.sort_values('TransactionDT')['isFraud']\nX_test = df_test.sort_values('TransactionDT').drop(['TransactionDT'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del df_train\n\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n#This call generates the Model code\n#def callTPOTTrainer():\n#    pipeline_optimizer = TPOTClassifier(generations=8, population_size=20, cv=3,crossover_rate=0.3, memory='auto',n_jobs=-1, early_stop=5,mutation_rate=0.7, \n#                                    random_state=42, verbosity=2, template='Selector-Transformer-Classifier')\n#    pipeline_optimizer.fit(X_train.values, y_train)\n#    print(pipeline_optimizer.score(X_val, y_val))\n#    pipeline_optimizer.export('IEEE_Frauds_tpot_exported_pipeline_MDR_2ndround.py')\n#Parallel(n_jobs=7)(delayed(callTPOTTrainer()))\n#Parallel(n_jobs=7,prefer=\"threads\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.tree import DecisionTreeClassifier\ntry:\n    from sklearn.impute import SimpleImputer as Imputer\nexcept ImportError:\n    from sklearn.preprocessing import Imputer\n\n# NOTE: Make sure that the class is labeled 'target' in the data file\nfeatures = X_train\ntraining_features, testing_features, training_target, testing_target = \\\n            train_test_split(features, y_train, random_state=42)\n\nimputer = Imputer(strategy=\"median\",missing_values=np.NaN)\nimputer.fit(training_features)\ntraining_features = training_features.fillna(training_features.median())#imputer.transform(training_features)\ntesting_features = testing_features.fillna(testing_features.median())#imputer.transform(testing_features)\n\n# Average CV score on the training set was:0.9721091430442194\nexported_pipeline = make_pipeline(\n    VarianceThreshold(threshold=0.1),\n    Normalizer(norm=\"l1\"),\n    DecisionTreeClassifier(criterion=\"entropy\", max_depth=10, min_samples_leaf=5, min_samples_split=3)\n)\n\nexported_pipeline.fit(training_features, training_target)\n\nscore_from_training = exported_pipeline.score(testing_features,testing_target)\nprint(\"Score= \" + str(score_from_training))\n\ntesting_feature = X_test\ntesting_features = testing_feature.fillna(testing_feature.median())#imputer.transform(testing_features)\n#------------------ Predict for Submission ---------------------------\nresults = exported_pipeline.predict(testing_features)\ndfIsFraud = pd.DataFrame(data={'TransactionID':X_test.index.values, 'isFraud':results})\ndfIsFraud.to_csv('submission_TPOT_DecisionTreeClassifier_2ndround.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}